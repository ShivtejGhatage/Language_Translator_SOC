{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Language Translator\n",
        "\n",
        "Shivtej Ghatage\n",
        "\n",
        "23B3950\n",
        "\n",
        "Summer of Code 2024"
      ],
      "metadata": {
        "id": "nCLXD9hII1pF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import os"
      ],
      "metadata": {
        "id": "olau6SWxd94E"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rRY96etbNSwB"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "epochs = 10\n",
        "latent_dim = 256\n",
        "num_samples = 20000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open('deu.txt', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "\n",
        "\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaXPf-D0d17Z",
        "outputId": "e10fb58c-90d9-4ddf-b643-f46df63d38c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 20000\n",
            "Number of unique input tokens: 72\n",
            "Number of unique output tokens: 89\n",
            "Max sequence length for inputs: 17\n",
            "Max sequence length for outputs: 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "metadata": {
        "id": "CZFNp2XzeDeB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "\n",
        "model.save(\"model.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZfSglKGeGXH",
        "outputId": "c7c50359-5b8e-49fa-b685-f0705ef0d4d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.8016 - loss: 0.8003 - val_accuracy: 0.8483 - val_loss: 0.5229\n",
            "Epoch 2/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.8770 - loss: 0.4299 - val_accuracy: 0.8652 - val_loss: 0.4595\n",
            "Epoch 3/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8918 - loss: 0.3724 - val_accuracy: 0.8785 - val_loss: 0.4158\n",
            "Epoch 4/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9011 - loss: 0.3391 - val_accuracy: 0.8848 - val_loss: 0.3963\n",
            "Epoch 5/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.9075 - loss: 0.3156 - val_accuracy: 0.8906 - val_loss: 0.3757\n",
            "Epoch 6/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9134 - loss: 0.2955 - val_accuracy: 0.8941 - val_loss: 0.3629\n",
            "Epoch 7/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.9183 - loss: 0.2794 - val_accuracy: 0.8987 - val_loss: 0.3488\n",
            "Epoch 8/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9219 - loss: 0.2667 - val_accuracy: 0.9011 - val_loss: 0.3400\n",
            "Epoch 9/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9255 - loss: 0.2542 - val_accuracy: 0.9032 - val_loss: 0.3350\n",
            "Epoch 10/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.9276 - loss: 0.2453 - val_accuracy: 0.9050 - val_loss: 0.3304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"model.keras\")\n",
        "\n",
        "encoder_inputs = model.input[0]\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value, verbose=0\n",
        "        )\n",
        "\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "bgh5xqCHeLe6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in range(20):\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(\"*************\")\n",
        "    print(\"English sentence:\", input_texts[seq_index])\n",
        "    print(\"German sentence:\", decoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWk1RCYxeaeV",
        "outputId": "b64a24be-afe5-4e79-c6f2-6983d1d84fcf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************\n",
            "English sentence: Go.\n",
            "German sentence: Geh schlafen!\n",
            "\n",
            "*************\n",
            "English sentence: Hi.\n",
            "German sentence: Schauen Sie auf!\n",
            "\n",
            "*************\n",
            "English sentence: Hi.\n",
            "German sentence: Schauen Sie auf!\n",
            "\n",
            "*************\n",
            "English sentence: Run!\n",
            "German sentence: Haben Sie mir gesunden!\n",
            "\n",
            "*************\n",
            "English sentence: Run.\n",
            "German sentence: Seien Sie sich!\n",
            "\n",
            "*************\n",
            "English sentence: Wow!\n",
            "German sentence: Wurdet es ausheren?\n",
            "\n",
            "*************\n",
            "English sentence: Wow!\n",
            "German sentence: Wurdet es ausheren?\n",
            "\n",
            "*************\n",
            "English sentence: Duck!\n",
            "German sentence: Seien Sie nicht!\n",
            "\n",
            "*************\n",
            "English sentence: Fire!\n",
            "German sentence: Seien Sie sich!\n",
            "\n",
            "*************\n",
            "English sentence: Help!\n",
            "German sentence: Schauen Sie auf!\n",
            "\n",
            "*************\n",
            "English sentence: Help!\n",
            "German sentence: Schauen Sie auf!\n",
            "\n",
            "*************\n",
            "English sentence: Hide.\n",
            "German sentence: Sei runter!\n",
            "\n",
            "*************\n",
            "English sentence: Hide.\n",
            "German sentence: Sei runter!\n",
            "\n",
            "*************\n",
            "English sentence: Stay.\n",
            "German sentence: Seien Sie sich!\n",
            "\n",
            "*************\n",
            "English sentence: Stop!\n",
            "German sentence: Seien Sie sich!\n",
            "\n",
            "*************\n",
            "English sentence: Stop!\n",
            "German sentence: Seien Sie sich!\n",
            "\n",
            "*************\n",
            "English sentence: Wait!\n",
            "German sentence: Wartet mal!\n",
            "\n",
            "*************\n",
            "English sentence: Wait.\n",
            "German sentence: Wartet mal!\n",
            "\n",
            "*************\n",
            "English sentence: Begin.\n",
            "German sentence: Schaut auf zu lächern.\n",
            "\n",
            "*************\n",
            "English sentence: Do it.\n",
            "German sentence: Sei nicht an.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}